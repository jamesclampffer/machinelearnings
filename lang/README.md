# Twelve Angry LLMs

This project simulates a jury deliberation, but with a twist: all the jurors are Large Language Models.

##  Objectives

This side project was primarily developed to achieve several key objectives:

- Gain a practical feel for this technology, its associated tooling, and hardware requirements for inference.
- Better understand the real-world costs of inference, particularly when seeking alternatives to major cloud providers due to quota or availability limitations for accelerated instances.
- Observe how quickly LLM-generated context begins to hallucinate interesting backstory details, and whether this effect compounds when nearly all prior text in the context window was generated by the same LLM.
- Investigate if sufficiently capable models can infer or emulate the story plot from context given decades of narrative adaptations that likely made it into training data.
- Play around with quantization levels and their impact on generated content fidelity. For instance, the output from 3-bit quantized models has an uncanny resemblance to the speech issues sometimes exhibited after a TBI. 
- Provide concrete examples of certain open-frontier models exhibiting peculiar behaviors in a very obvious manner.
- A few years ago I heard that engineering jobs will be disappearing any day now. After a few years it must be _really_ close to happening, right? I need an education in the extemely scientific discipline of "Prompt Engineering"(TM). I only know how to write concise instructions with associated examples for people. I hear this rigorous engineering discipline is far more complicated than that (because computers).


## Design

The core design revolves around twelve "AngryPerson" instances, each seeded with a the juror's personality summary sourced from Wikipedia. All agents receive a common prompt about being on a jury, interpreting facts and discussion through their designated persona. Jurors participate in the discussion round-robin, contributing to a shared conversation history.

A rapid stand-up of a functional program was achieved by:

- Utilizing readily available, production-quality AI models.
- Implementing a core context amalgamation process to dynamically build each juror's prompt. This is the interesting part IMO. This process integrates:
  - The juror's immutable personality description.
  - General jury instructions and behavioral guidelines.
  - Relevant snippets of the plot to establish common facts of the trial.
  - The shared conversation history, with more recent turns prioritized.
- Intelligently adapting to available hardware, dynamically selecting smaller, more efficient models for background tasks and larger, "smarter" models for generating primary dialog, based on detected VRAM or system RAM.

## Components

The project is structured around several key components:

- **Hardware Probing & Model Selection**: At startup, the script attempts to detect available VRAM (via nvidia_smi) or system RAM (via psutil). This information is then used to automatically select default QUICK_MODEL (for lightweight tasks) and SMART_MODEL (for complex dialog generation) from available Ollama local models (e.g., Gemma3).
- `extract_question_target`: A utility function that uses a smaller AI model to discern if a question in the ongoing dialogue is directed at a specific juror, aiding in potential turn scheduling.
- `PLOT_SCAFFOLD`: A hardcoded list of narrative snippets outlining the core plot of 12 Angry Men, designed to provide essential context to the AI agents.
- `DiscussionContext`: Manages the rolling history of shared dialogue. It has the capability to summarize prior statements (though currently optional) to stay within context window limits.
- `ContextAmalgamator`: Responsible for dynamically assembling the specific, current context window for any given juror, combining their personality, general instructions, plot details, and the evolving conversation history. History is added in a way that respects temporal order of rooting prompts.
  -  A logical extension would be to allow each to have a history such that things can be forgotten on a per-person basis in a manner that crudely emulates working memory. Then I can rename this to Twelve Angry&Forgetful LLMs.
- `jurors`: A hardcoded list of 12 brief personality descriptions for each juror, sourced from Wikipedia.
- `AngryPerson`: Represents an individual juror. Each instance holds its specific personality and handles interactions by querying the ollama server with its tailored context, then contributing its response to the shared DiscussionContext.
- **Run loop**: Jurors are then picked round robin to participate in the discussion.
- The shared discussion from the `ContextAmalgamator` is fed to the model.
- Scheduling needs improvement, if a juror is asked a question they should be scheduled to interact next. `extract_question_target` is the basis for this

## Future things to try:
- User specific hidden context history and multishot prompt expansion. I.e. a simple "reasoning model" framework.
- Allow bits of context to be forgotten on a per-agent basis.
 - Use personality to drive what history gets attention vs. what is omitted as it ages out.
 - Add intentionally misremembered history.
- Trickle in details of the plot over time in smaller chunks.

